{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a858997d-1eb2-4616-a26f-dcc2e2d83586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from idsds.models.resnet import resnet18, resnet50, resnet101, resnet152, wide_resnet50_2\n",
    "from idsds.models.vgg import vgg16, vgg16_bn, vgg13, vgg19, vgg11\n",
    "from idsds.models.ViT.ViT_new import vit_base_patch16_224\n",
    "from idsds.models.ViT.ViT_LRP import vit_base_patch16_224 as vit_LRP\n",
    "from idsds.models.bagnets.pytorchnet import bagnet33\n",
    "from idsds.models.xdnns.xfixup_resnet import xfixup_resnet50, fixup_resnet50\n",
    "from idsds.models.xdnns.xvgg import xvgg16\n",
    "from idsds.models.bcos_v2.bcos_resnet import resnet50 as bcos_resnet50\n",
    "from idsds.models.bcos_v2.bcos_resnet import resnet18 as bcos_resnet18\n",
    "\n",
    "import utils\n",
    "\n",
    "original_models = \"/workspace/hd/original/\"\n",
    "tuned_models = \"/workspace/hd/tuned/\"\n",
    "\n",
    "test_loader = utils.get_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0f57030-1810-43bc-bcfc-be3d5bc37a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_mad_attr(model1, model2, attr_fn, loader):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model1.to(device).eval()\n",
    "    model2.to(device).eval()\n",
    "\n",
    "    total_mad = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    cam1 = attr_fn(model1)\n",
    "    cam2 = attr_fn(model2)\n",
    "\n",
    "    for images, _ in loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        for i in range(images.size(0)):\n",
    "            input_tensor = images[i].unsqueeze(0)\n",
    "    \n",
    "            output1 = model1(input_tensor)\n",
    "            pred_class1 = output1.argmax(dim=1)[0].item()\n",
    "            attribution_map1 = cam1(pred_class1, output1)[0]\n",
    "        \n",
    "            output2 = model2(input_tensor)\n",
    "            pred_class2 = output2.argmax(dim=1)[0].item()\n",
    "            attribution_map2 = cam2(pred_class2, output2)[0]\n",
    "        \n",
    "            if attribution_map1.ndim == 3 and attribution_map1.shape[0] == 1:\n",
    "                attribution_map1 = attribution_map1.squeeze(0)\n",
    "            if attribution_map2.ndim == 3 and attribution_map2.shape[0] == 1:\n",
    "                attribution_map2 = attribution_map2.squeeze(0)\n",
    "            \n",
    "            map1_resized = F.interpolate(attribution_map1.unsqueeze(0).unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze()\n",
    "            map2_resized = F.interpolate(attribution_map2.unsqueeze(0).unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze()\n",
    "        \n",
    "            total_mad += torch.abs(map1_resized - map2_resized).mean().item()\n",
    "        num_samples += images.size(0)\n",
    "        print(f\"{num_samples} {total_mad}\")\n",
    "\n",
    "    mad = total_mad / num_samples\n",
    "    print(f\"Mean Absolute Difference between attribution maps: {mad}\")\n",
    "\n",
    "test_loader = get_loader(batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "433be707-0075-44ee-b8e9-750d8e095cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42/1808958144.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n",
      "WARNING:root:no value was provided for `target_layer`, thus set to 'layer4'.\n",
      "WARNING:root:no value was provided for `target_layer`, thus set to 'layer4'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 4.889074240811169\n",
      "200 8.708673507906497\n",
      "300 13.189132812432945\n",
      "400 18.303034431301057\n",
      "500 23.023825705051422\n",
      "600 28.772354780696332\n",
      "700 33.559516292996705\n",
      "800 38.5736175570637\n",
      "900 43.79189453180879\n",
      "1000 48.759562991559505\n",
      "1100 54.14293042104691\n",
      "1200 60.50546339992434\n",
      "1300 65.45150360558182\n",
      "1400 69.92538102716208\n",
      "1500 74.60425293352455\n",
      "1600 79.92344077676535\n",
      "1700 84.79647032823414\n",
      "1800 89.7522300593555\n",
      "1900 93.77192197926342\n",
      "2000 97.48797635454684\n",
      "2100 102.91816969402134\n",
      "2200 108.09968297276646\n",
      "2300 113.0479286890477\n",
      "2400 117.74490522779524\n",
      "2500 123.32907906360924\n",
      "2600 127.93321824260056\n",
      "2700 132.50750592537224\n",
      "2800 136.89259670861065\n",
      "2900 141.8336002510041\n",
      "3000 146.1190961105749\n",
      "3100 150.85396315902472\n",
      "3200 155.17801814898849\n",
      "3300 159.8392039416358\n",
      "3400 165.02810506056994\n",
      "3500 170.41931820567697\n",
      "3600 174.66147010121495\n",
      "3700 179.55783457309008\n",
      "3800 183.8782892683521\n",
      "3900 188.3820141190663\n",
      "4000 194.48068280518055\n",
      "4100 200.21075364761055\n",
      "4200 208.47729245759547\n",
      "4300 214.8367188833654\n",
      "4400 221.23727911431342\n",
      "4500 227.32464208826423\n",
      "4600 234.53476577345282\n",
      "4700 241.25861244648695\n",
      "4800 248.0548729337752\n",
      "4900 255.81836637295783\n",
      "5000 263.5959523897618\n",
      "5100 270.92298518680036\n",
      "5200 278.209639669396\n",
      "5300 284.83186712581664\n",
      "5400 291.79587319120765\n",
      "5500 298.50546951405704\n",
      "5600 304.7890853770077\n",
      "5700 310.4972224710509\n",
      "5800 316.6282814787701\n",
      "5900 322.7007934814319\n",
      "6000 329.6981317317113\n",
      "6100 335.8624115232378\n",
      "6200 343.2943719793111\n",
      "6300 349.44570284243673\n",
      "6400 356.0182848377153\n",
      "6500 362.4713554326445\n",
      "6600 368.64793384075165\n",
      "6700 374.70878368616104\n",
      "6800 380.92407795693725\n",
      "6900 386.66186644509435\n",
      "7000 393.01276405900717\n",
      "7100 399.57158245146275\n",
      "7200 406.3765933867544\n",
      "7300 412.022981852293\n",
      "7400 417.7051437422633\n",
      "7500 424.8541002376005\n",
      "7600 431.5505640935153\n",
      "7700 437.53488049376756\n",
      "7800 443.5162784717977\n",
      "7900 450.30045045912266\n",
      "8000 456.0876220613718\n",
      "8100 462.9277798719704\n",
      "8200 469.76578681916\n",
      "8300 476.36280527710915\n",
      "8400 482.8548998236656\n",
      "8500 491.745025806129\n",
      "8600 500.2639962481335\n",
      "8700 507.0248948922381\n",
      "8800 512.7675238968804\n",
      "8900 521.3255380988121\n",
      "9000 529.1916487822309\n",
      "9100 536.9275852926075\n",
      "9200 543.7249078061432\n",
      "9300 551.4885305576026\n",
      "9400 557.1350898845121\n",
      "9500 563.3844709480181\n",
      "9600 570.0484791817144\n",
      "9700 576.0701611489058\n",
      "9800 582.5799925904721\n",
      "9900 587.4686834663153\n",
      "10000 593.6230414547026\n",
      "Mean Absolute Difference between attribution maps: 0.05936230414547026\n"
     ]
    }
   ],
   "source": [
    "from torchcam.methods import GradCAM\n",
    "\n",
    "resnet50_ood = resnet.resnet50(pretrained=True)\n",
    "resnet50_id = resnet.resnet50(pretrained=True)\n",
    "resnet50_id = lsd(\n",
    "    tuned_models + \"resnet50_imagenet1000_lr0.001_epochs30_step10_checkpoint_best.pth.tar\", \n",
    "    resnet50_id\n",
    ")\n",
    "compare_mad_attr(resnet50_ood, resnet50_id, GradCAM, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661eaf7-c241-445c-9cab-9f96b0191d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
