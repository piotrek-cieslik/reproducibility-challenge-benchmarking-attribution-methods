{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94fbd905-7a61-4b5f-83a0-3cbc112c6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from idsds.models.resnet import resnet18, resnet50, resnet101, resnet152, wide_resnet50_2\n",
    "from idsds.models.vgg import vgg16, vgg16_bn, vgg13, vgg19, vgg11\n",
    "from idsds.models.ViT.ViT_new import vit_base_patch16_224\n",
    "from idsds.models.ViT.ViT_LRP import vit_base_patch16_224 as vit_LRP\n",
    "from idsds.models.bagnets.pytorchnet import bagnet33\n",
    "from idsds.models.xdnns.xfixup_resnet import xfixup_resnet50, fixup_resnet50\n",
    "from idsds.models.xdnns.xvgg import xvgg16\n",
    "from idsds.models.bcos_v2.bcos_resnet import resnet50 as bcos_resnet50\n",
    "from idsds.models.bcos_v2.bcos_resnet import resnet18 as bcos_resnet18\n",
    "\n",
    "import utils\n",
    "\n",
    "original_models = \"/workspace/hd/original/\"\n",
    "tuned_models = \"/workspace/hd/tuned/\"\n",
    "\n",
    "test_loader = utils.get_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8db5a9-a3df-4a10-bbc0-e1c7e3a4edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compare_mad(model1, model2, loader):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model1.to(device).eval()\n",
    "    model2.to(device).eval()\n",
    "    \n",
    "    num_samples = 0\n",
    "    logit_mad_total = 0\n",
    "    softmax_mad_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "    \n",
    "            # logits\n",
    "            logits1 = model1(images)\n",
    "            logits2 = model2(images)\n",
    "\n",
    "            # logit mad\n",
    "            logit_mad = torch.abs(logits1 - logits2).mean(dim=1)\n",
    "            logit_mad_total += logit_mad.sum().item()\n",
    "    \n",
    "            # softmax\n",
    "            probs1 = F.softmax(logits1, dim=1)\n",
    "            probs2 = F.softmax(logits2, dim=1)\n",
    "    \n",
    "            # softmax mad\n",
    "            softmax_mad = torch.abs(probs1 - probs2).mean(dim=1)\n",
    "            softmax_mad_total += softmax_mad.sum().item()\n",
    "            \n",
    "            num_samples += images.size(0)\n",
    "            \n",
    "    logit_mad_score = logit_mad_total / num_samples\n",
    "    softmax_mad_score = softmax_mad_total / num_samples\n",
    "    print(f\"Softmax MAD: {softmax_mad_score}\")\n",
    "    print(f\"Logit MAD:  {logit_mad_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a377a53-e584-42bc-a631-3f9565db6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2455/3000642689.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax MAD: 0.0002470408531837165\n",
      "Logit MAD:  0.4373722342967987\n"
     ]
    }
   ],
   "source": [
    "resnet18_ood = resnet18(pretrained=True)\n",
    "resnet18_id = resnet18(pretrained=True)\n",
    "resnet18_id = utils.load_state_dict(\n",
    "    tuned_models + \"resnet18_imagenet1000_lr0.001_epochs30_step10_checkpoint_best.pth.tar\", \n",
    "    resnet18_id\n",
    ")\n",
    "compare_mad(resnet18_ood, resnet18_id, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278e90bf-34b3-41e1-93c3-b2476bb45627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2455/3629283876.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "fixup_resnet50_ood = fixup_resnet50()\n",
    "fixup_resnet50_id = fixup_resnet50()\n",
    "fixup_resnet50_id = utils.load_state_dict(\n",
    "    tuned_models + \"fixup_resnet50_imagenet1000_lr0.001_epochs30_step10_checkpoint_best.pth.tar\", \n",
    "    fixup_resnet50_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b4c2b1-4112-4067-b638-76c427976034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2455/41557205.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "x_resnet50_ood = xfixup_resnet50()\n",
    "x_resnet50_id = xfixup_resnet50()\n",
    "x_resnet50_id = utils.load_state_dict(\n",
    "    tuned_models + \"xresnet50_imagenet1000_lr0.001_epochs30_step10_checkpoint_best.pth.tar\", \n",
    "    x_resnet50_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "640ff649-c8d9-41a0-9fb7-db2743545812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2455/41557205.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "x_vgg16_ood = xvgg16(pretrained=True)\n",
    "x_vgg16_id = xvgg16(pretrained=True)\n",
    "x_vgg16_id = utils.load_state_dict(\n",
    "    tuned_models + \"xvgg16_imagenet1000_lr0.001_epochs30_step10_checkpoint_best.pth.tar\", \n",
    "    x_vgg16_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6df03eb2-0190-4781-a513-3510b744a597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOADED\n",
      "MODEL LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2455/41557205.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m bagnet33_id = bagnet33(pretrained=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m bagnet33_id = lsd(\n\u001b[32m      4\u001b[39m     tuned_models + \u001b[33m\"\u001b[39m\u001b[33mbagnet33_imagenet1000_lr0.001_epochs30_step10_checkpoint_best.pth.tar\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      5\u001b[39m     bagnet33_id\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mcompare_mad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbagnet33_ood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbagnet33_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mcompare_mad\u001b[39m\u001b[34m(model1, model2, loader)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# logit mad\u001b[39;00m\n\u001b[32m     22\u001b[39m logit_mad = torch.abs(logits1 - logits2).mean(dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m logit_mad_total += \u001b[43mlogit_mad\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# softmax\u001b[39;00m\n\u001b[32m     26\u001b[39m probs1 = F.softmax(logits1, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "bagnet33_ood = bagnet33(pretrained=True)\n",
    "bagnet33_id = bagnet33(pretrained=True)\n",
    "bagnet33_id = utils.load_state_dict(\n",
    "    tuned_models + \"bagnet33_imagenet1000_lr0.001_epochs30_step10_checkpoint_best.pth.tar\", \n",
    "    bagnet33_id\n",
    ")\n",
    "compare_mad(bagnet33_ood, bagnet33_id, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f294a-402d-4760-8185-80202866bdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
